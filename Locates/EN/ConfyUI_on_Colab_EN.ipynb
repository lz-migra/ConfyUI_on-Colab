{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title # üõ†Ô∏è ComfyUI Configuration Panel\n",
        "#@markdown ---\n",
        "#@markdown ### üìÅ Storage Management (Google Drive)\n",
        "#@markdown Choose how you want to handle your files. Mounting Drive allows your models and results to persist after closing Colab.\n",
        "MODO_DRIVE = \"SOLO_LOCAL\" #@param [\"MONTAR\", \"DESMONTAR\", \"SOLO_LOCAL\"]\n",
        "USAR_DRIVE_PARA_COMFY = True #@param {type:\"boolean\"}\n",
        "#@markdown > **Note:** If you check the box above, ComfyUI will be installed in `/content/drive/MyDrive/AI/ComfyUI`. This saves time in future sessions as you won't have to re-download everything.\n",
        "RUTA_PERSONALIZADA_DRIVE = \"AI/ComfyUI\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### üîÑ Updates and Maintenance\n",
        "ACTUALIZAR_COMFY = True #@param {type:\"boolean\"}\n",
        "#@markdown > **Update:** Automatically downloads the latest version of ComfyUI from GitHub.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### üß† Model Installation and AI\n",
        "#@markdown Select which models you want to pre-install to start working immediately.\n",
        "INSTALAR_QWEN_VL = False #@param {type:\"boolean\"}\n",
        "#@markdown > **Qwen VL/2509 Image Editing:** Installs the necessary models to use these Workflows.\n",
        "#@markdown >\n",
        "#@markdown > An advanced multimodal model capable of \"understanding\" images and editing them following complex instructions. Requires specific nodes that will be installed automatically.\n",
        "#@markdown >\n",
        "#@markdown > <font color='red'>Note: This model is very heavy, so Google Colab free machines usually cannot handle it (Stops due to lack of RAM).</font>\n",
        "\n",
        "INSTALAR_SD15_BASE = False #@param {type:\"boolean\"}\n",
        "#@markdown > **Stable Diffusion 1.5:** The gold standard for image generation. Includes the base model and a VAE to improve colors and faces.\n",
        "\n",
        "INSTALAR_PROTOVISION_XL = False #@param {type:\"boolean\"}\n",
        "INSTALAR_JUGGERNAUT_XL_HYPER = False #@param {type:\"boolean\"}\n",
        "INSTALAR_JUGGERNAUT_X = False #@param {type:\"boolean\"}\n",
        "INSTALAR_JUGGERNAUT_V8 = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### üì¶ Install Custom Models\n",
        "#@markdown Enter the list of models in JSON format.\n",
        "#@markdown > You can generate the JSON string with the correct format via the following Google Apps Script project:\n",
        "#@markdown > ### [üëâ Click HERE to open the tool](https://script.google.com/macros/s/AKfycbzmfmxfFRKvlnwlDuHNwOhWqEzYd90f1YKaQxSuFQ3o8HyQW_oHZZgPo9j4vUQlJ7ZI/exec)\n",
        "\n",
        "MODELOS_PERSONALIZADOS = \"[]\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### üöÄ Execution Configuration\n",
        "\n",
        "USAR_LOWVRAM = False #@param {type:\"boolean\"}\n",
        "#@markdown > **üìâ Low VRAM:** Enable this if Colab closes unexpectedly or you run out of memory. Helps manage resources better.\n",
        "\n",
        "USAR_CPU_ONLY = True #@param {type:\"boolean\"}\n",
        "#@markdown > **üêå CPU Only:** Enable this if you don't have access to a GPU. Generation will be extremely slow.\n",
        "\n",
        "TIPO_TUNEL = \"LOCALTUNNEL\" #@param [\"CLOUDFLARE\", \"LOCALTUNNEL\"]\n",
        "#@markdown > **üåê Tunnel Type:** Select the connection method to access the web interface.\n",
        "\n",
        "ARGUMENTOS_ADICIONALES = \"\" #@param {type:\"string\"}\n",
        "#@markdown > **‚å®Ô∏è Additional Arguments:** Insert extra commands to modify program behavior.\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    if not USAR_CPU_ONLY:\n",
        "        print(\"\\n\" + \"!\"*60)\n",
        "        print(\"‚ùå CRITICAL ERROR: NO GPU DETECTED\")\n",
        "        print(\"------------------------------------------------------------\")\n",
        "        print(\"ComfyUI requires a GPU to function. You are currently using CPU.\")\n",
        "        print(\"üëâ Go to: Runtime > Change runtime type\")\n",
        "        print(\"üëâ Select 'T4 GPU' in Hardware accelerator.\")\n",
        "        print(\"!\"*60 + \"\\n\")\n",
        "        raise RuntimeError(\"You must select a GPU (T4) environment to continue.\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è RUNNING IN CPU MODE: Image generation will be very slow.\")\n",
        "\n",
        "if MODO_DRIVE == \"MONTAR\":\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "elif MODO_DRIVE == \"DESMONTAR\":\n",
        "  try:\n",
        "    drive.flush_and_unmount()\n",
        "  except ValueError:\n",
        "    pass\n",
        "  get_ipython().system_raw(\"rm -rf /root/.config/Google/DriveFS\")\n",
        "\n",
        "WORKSPACE = '/content/ComfyUI'\n",
        "if MODO_DRIVE == \"MONTAR\" and USAR_DRIVE_PARA_COMFY:\n",
        "    WORKSPACE = \"/content/drive/MyDrive/\" + RUTA_PERSONALIZADA_DRIVE\n",
        "\n",
        "if not os.path.exists(WORKSPACE):\n",
        "    print(\"-= Initial setup ComfyUI =-\")\n",
        "    !git clone https://github.com/comfyanonymous/ComfyUI {WORKSPACE}\n",
        "else:\n",
        "    if ACTUALIZAR_COMFY:\n",
        "        print(\"-= Updating ComfyUI =-\")\n",
        "        %cd {WORKSPACE}\n",
        "        !git pull\n",
        "\n",
        "%cd {WORKSPACE}\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "%cd {WORKSPACE}\n",
        "\n",
        "\n",
        "\n",
        "%cd {WORKSPACE}\n",
        "# Install Aria2\n",
        "!apt-get -y install -qq aria2\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "CIVITAI_API_TOKEN = userdata.get('CIVITAI_API_TOKEN')\n",
        "print(\"Loaded API key:\", \"‚úÖ\" if CIVITAI_API_TOKEN else \"‚ùå Not found\")\n",
        "\n",
        "# Install custom nodes\n",
        "\n",
        "def install_custom_node(url):\n",
        "  %cd {WORKSPACE}/custom_nodes\n",
        "  !git clone {url}\n",
        "\n",
        "def downloadModel(url, filename = None):\n",
        "  if 'huggingface.co' in url:\n",
        "    if filename is None:\n",
        "      filename = url.split('/')[-1]\n",
        "      filename = filename.removesuffix('?download=true')\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url}  -o {filename}\n",
        "  else:\n",
        "    # civitai\n",
        "    if filename:\n",
        "      !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url}?token={CIVITAI_API_TOKEN} -o {filename}\n",
        "    else:\n",
        "      !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url}?token={CIVITAI_API_TOKEN}\n",
        "\n",
        "\n",
        "# install custom nodes\n",
        "#install_custom_node('https://github.com/ltdrdata/ComfyUI-Manager.git')\n",
        "#install_custom_node('https://github.com/ltdrdata/ComfyUI-Impact-Pack')\n",
        "\n",
        "\n",
        "# download models\n",
        "%cd ./models/checkpoints\n",
        "\n",
        "# CyberRealistic Pony\n",
        "downloadModel('https://civitai.com/api/download/models/2071650')\n",
        "\n",
        "# Protovision XL\n",
        "if INSTALAR_PROTOVISION_XL:\n",
        "    downloadModel('https://civitai.com/api/download/models/201514')\n",
        "# Juggernaut XL Hyper\n",
        "if INSTALAR_JUGGERNAUT_XL_HYPER:\n",
        "    downloadModel('https://civitai.com/api/download/models/471120')\n",
        "# Juppernaut X\n",
        "if INSTALAR_JUGGERNAUT_X:\n",
        "    downloadModel('https://civitai.com/api/download/models/456194')\n",
        "# Juggernaut v8\n",
        "if INSTALAR_JUGGERNAUT_V8:\n",
        "    downloadModel('https://civitai.com/api/download/models/288982')\n",
        "\n",
        "%cd {WORKSPACE}\n",
        "\n",
        "\n",
        "\n",
        "if INSTALAR_QWEN_VL:\n",
        "    # 1. Configuraci√≥n de carpetas y descargas de Qwen\n",
        "    # ----------------------------------------------------------------\n",
        "\n",
        "    # VAE\n",
        "    %cd {WORKSPACE}/models/vae\n",
        "    downloadModel('https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors')\n",
        "\n",
        "    # DIFFUSION MODELS (Unet)\n",
        "    # Nota: Si la carpeta no existe, la creamos\n",
        "    !mkdir -p {WORKSPACE}/models/diffusion_models\n",
        "    %cd {WORKSPACE}/models/diffusion_models\n",
        "    downloadModel('https://huggingface.co/Comfy-Org/Qwen-Image-Edit_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_edit_fp8_e4m3fn.safetensors')\n",
        "\n",
        "    # TEXT ENCODERS\n",
        "    !mkdir -p {WORKSPACE}/models/text_encoders\n",
        "    %cd {WORKSPACE}/models/text_encoders\n",
        "    downloadModel('https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors')\n",
        "\n",
        "    # LORAS\n",
        "    %cd {WORKSPACE}/models/loras\n",
        "    downloadModel('https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Edit-Lightning-4steps-V1.0-bf16.safetensors')\n",
        "\n",
        "    # 2. Instalaci√≥n del Nodo Personalizado (Obligatorio para que funcione el workflow)\n",
        "    # ----------------------------------------------------------------\n",
        "    %cd {WORKSPACE}/custom_nodes\n",
        "    # Clonamos el repositorio oficial que maneja estos modelos de Qwen\n",
        "    !git clone https://github.com/Comfy-Org/ComfyUI-Qwen-VL-API.git 2>/dev/null || echo \"üü¢ Qwen/2095 Image Editing - Installation Finished\"\n",
        "\n",
        "    # Volver al inicio\n",
        "    %cd {WORKSPACE}\n",
        "\n",
        "if INSTALAR_SD15_BASE:\n",
        "    # --- Descarga de Modelos SD 1.5 (Optimizados) ---\n",
        "\n",
        "    # SD1.5 Pruned (Versi√≥n Safetensors - M√°s r√°pida y segura)\n",
        "    %cd {WORKSPACE}/models/checkpoints\n",
        "    downloadModel('https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors')\n",
        "\n",
        "    # AbyssOrangeMix2 (Anime Style)\n",
        "    downloadModel('https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors')\n",
        "\n",
        "    # VAE Standard (Mejora el color y detalles en SD 1.5)\n",
        "    %cd {WORKSPACE}/models/vae\n",
        "    downloadModel('https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors')\n",
        "\n",
        "    %cd {WORKSPACE}\n",
        "\n",
        "if MODELOS_PERSONALIZADOS:\n",
        "    import json\n",
        "    print(\"‚¨áÔ∏è Downloading custom models...\")\n",
        "    try:\n",
        "        custom_models = json.loads(MODELOS_PERSONALIZADOS)\n",
        "        if isinstance(custom_models, list):\n",
        "            for model in custom_models:\n",
        "                path_str = model.get(\"ruta\", \"\").strip()\n",
        "                url = model.get(\"link\", \"\").strip()\n",
        "\n",
        "                if path_str and url:\n",
        "                    if \"/\" in path_str:\n",
        "                        folder_part, filename_part = path_str.rsplit(\"/\", 1)\n",
        "                        folder_part = folder_part.strip()\n",
        "                        filename_part = filename_part.strip()\n",
        "\n",
        "                        target_path = f\"{WORKSPACE}/models/{folder_part}\"\n",
        "                        !mkdir -p {target_path}\n",
        "                        %cd {target_path}\n",
        "                        downloadModel(url, filename_part)\n",
        "                    else:\n",
        "                        print(f\"‚ö†Ô∏è Incorrect format in path: {path_str}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è Error: MODELOS_PERSONALIZADOS is not a valid JSON.\")\n",
        "\n",
        "    %cd {WORKSPACE}\n",
        "\n",
        "\n",
        "!ls -al ./models/checkpoints/\n",
        "\n",
        "\n",
        "if TIPO_TUNEL == \"CLOUDFLARE\":\n",
        "    !wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "    !dpkg -i cloudflared-linux-amd64.deb\n",
        "elif TIPO_TUNEL == \"LOCALTUNNEL\":\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "\n",
        "\n",
        "# --- CREACI√ìN DEL SCRIPT LANZADOR PERSISTENTE ---\n",
        "%cd {WORKSPACE}\n",
        "\n",
        "comfy_args = [\"python\", \"main.py\", \"--dont-print-server\"]\n",
        "if USAR_CPU_ONLY:\n",
        "    comfy_args.append(\"--cpu\")\n",
        "if USAR_LOWVRAM:\n",
        "    comfy_args.append(\"--lowvram\")\n",
        "if ARGUMENTOS_ADICIONALES:\n",
        "    comfy_args.extend(ARGUMENTOS_ADICIONALES.split())\n",
        "\n",
        "launcher_script = f\"\"\"\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "def launch_tunnel(port):\n",
        "    print(\"\\\\n[Tunnel] Waiting for ComfyUI to start...\")\n",
        "    while True:\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
        "            sock.close()\n",
        "            break\n",
        "        sock.close()\n",
        "        time.sleep(1)\n",
        "\n",
        "    tunnel_type = \"{TIPO_TUNEL}\"\n",
        "\n",
        "    if tunnel_type == \"CLOUDFLARE\":\n",
        "        proc = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{{}}\".format(port)],\n",
        "                                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        for line in proc.stderr:\n",
        "            if \"trycloudflare.com \" in line:\n",
        "                url = line.split(\"http\")[1].strip()\n",
        "                print(\"\\\\n\" + \"=\"*50)\n",
        "                print(f\"üîó ACCESS URL: http{{url}}\")\n",
        "                print(\"=\"*50 + \"\\\\n\")\n",
        "\n",
        "    elif tunnel_type == \"LOCALTUNNEL\":\n",
        "        try:\n",
        "            ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\\\n\")\n",
        "            print(\"\\\\n\" + \"=\"*50)\n",
        "            print(f\"üîê LOCALTUNNEL PASSWORD/IP: {{ip}}\")\n",
        "            print(\"=\"*50 + \"\\\\n\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        proc = subprocess.Popen([\"lt\", \"--port\", \"{{}}\".format(port)],\n",
        "                                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        for line in proc.stdout:\n",
        "            print(line, end='')\n",
        "            if \"your url is\" in line:\n",
        "                url = line.split(\"is:\")[1].strip()\n",
        "                print(\"\\\\n\" + \"=\"*50)\n",
        "                print(f\"üîó ACCESS URL: {{url}}\")\n",
        "                print(\"=\"*50 + \"\\\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    threading.Thread(target=launch_tunnel, args=(8188,), daemon=True).start()\n",
        "    subprocess.run({comfy_args})\n",
        "\"\"\"\n",
        "\n",
        "with open(\"colab_launcher.py\", \"w\") as f:\n",
        "    f.write(launcher_script)\n",
        "\n",
        "print(\"\\nüöÄ Starting ComfyUI...\")\n",
        "# Ejecutar en segundo plano con nohup para liberar la celda\n",
        "!nohup python -u colab_launcher.py > comfy.log 2>&1 &\n",
        "\n",
        "print(\"‚è≥ Waiting for Cloudflare URL (this may take a few seconds)...\")\n",
        "import time\n",
        "found = False\n",
        "file_pos = 0\n",
        "while not found:\n",
        "    if os.path.exists(\"comfy.log\"):\n",
        "        with open(\"comfy.log\", \"r\") as f:\n",
        "            f.seek(file_pos)\n",
        "            chunk = f.read()\n",
        "            if chunk:\n",
        "                print(chunk, end='', flush=True)\n",
        "                file_pos = f.tell()\n",
        "                if \"trycloudflare.com\" in chunk or \"your url is\" in chunk:\n",
        "                    for line in chunk.splitlines():\n",
        "                        if \"trycloudflare.com\" in line:\n",
        "                            url = line.split(\"http\")[1].strip()\n",
        "                            print(f\"\\n‚úÖ ACCESS URL: http{url}\")\n",
        "                            print(\"‚ö†Ô∏è The cell will close, but ComfyUI continues running in the background.\")\n",
        "                            found = True\n",
        "                            break\n",
        "                        elif \"your url is\" in line:\n",
        "                            url = line.split(\"is:\")[1].strip()\n",
        "                            print(f\"\\n‚úÖ ACCESS URL: {url}\")\n",
        "                            print(\"‚ö†Ô∏è The cell will close, but ComfyUI continues running in the background.\")\n",
        "                            found = True\n",
        "                            break\n",
        "    time.sleep(2)"
      ],
      "metadata": {
        "id": "erGgBwjKS9Rd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # üì¶ Install Custom Models Post-Execution\n",
        "#@markdown ---\n",
        "#@markdown ## If you need to install models after the main execution, you can do it from here:\n",
        "#@markdown Enter the list of models in JSON format in the box below, after placing the JSON line execute the cell.\n",
        "#@markdown > You can generate the JSON string with the correct format via the following Google Apps Script project:\n",
        "#@markdown > ### [üëâ Click HERE to open the tool](https://script.google.com/macros/s/AKfycbzmfmxfFRKvlnwlDuHNwOhWqEzYd90f1YKaQxSuFQ3o8HyQW_oHZZgPo9j4vUQlJ7ZI/exec)\n",
        "\n",
        "MODELOS_PERSONALIZADOS = \"[{\\\"id\\\":1,\\\"ruta\\\":\\\"vae/ae.safetensors\\\",\\\"link\\\":\\\"https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors\\\",\\\"workflow\\\":\\\"image_omnigen2_image_edit\\\"},{\\\"id\\\":2,\\\"ruta\\\":\\\"text_encoders/qwen_2.5_vl_fp16.safetensors\\\",\\\"link\\\":\\\"https://huggingface.co/Comfy-Org/Omnigen2_ComfyUI_repackaged/resolve/main/split_files/text_encoders/qwen_2.5_vl_fp16.safetensors\\\",\\\"workflow\\\":\\\"image_omnigen2_image_edit\\\"},{\\\"id\\\":3,\\\"ruta\\\":\\\"diffusion_models/omnigen2_fp16.safetensors\\\",\\\"link\\\":\\\"https://huggingface.co/Comfy-Org/Omnigen2_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/omnigen2_fp16.safetensors\\\",\\\"workflow\\\":\\\"image_omnigen2_image_edit\\\"}]\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown <font color='#888'>Note: Make sure you have executed the main cell first to define the `WORKSPACE` path.</font>\n",
        "\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "def descargar_modelos_custom():\n",
        "    if not MODELOS_PERSONALIZADOS or MODELOS_PERSONALIZADOS == \"[]\":\n",
        "        print(\"‚ÑπÔ∏è No models entered for download.\")\n",
        "        return\n",
        "\n",
        "    # Try to load Civitai token if it exists\n",
        "    try:\n",
        "        CIVITAI_API_TOKEN = userdata.get('CIVITAI_API_TOKEN')\n",
        "    except:\n",
        "        CIVITAI_API_TOKEN = \"\"\n",
        "        print(\"‚ö†Ô∏è Civitai Token not configured in 'Secrets'.\")\n",
        "\n",
        "    def download_logic(url, filename=None):\n",
        "        auth_token = f\"?token={CIVITAI_API_TOKEN}\" if CIVITAI_API_TOKEN and \"civitai.com\" in url else \"\"\n",
        "        output_cmd = f\"-o {filename}\" if filename else \"\"\n",
        "\n",
        "        # We use aria2 for fast and resilient downloads\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{url}{auth_token}\" {output_cmd}\n",
        "\n",
        "    print(\"‚¨áÔ∏è Starting custom model download...\")\n",
        "\n",
        "    try:\n",
        "        custom_models = json.loads(MODELOS_PERSONALIZADOS)\n",
        "        if isinstance(custom_models, list):\n",
        "            for model in custom_models:\n",
        "                path_str = model.get(\"ruta\", \"\").strip()\n",
        "                url = model.get(\"link\", \"\").strip()\n",
        "\n",
        "                if path_str and url:\n",
        "                    # Separate folder and filename\n",
        "                    if \"/\" in path_str:\n",
        "                        folder_part, filename_part = path_str.rsplit(\"/\", 1)\n",
        "                    else:\n",
        "                        folder_part = \"checkpoints\" # Default folder\n",
        "                        filename_part = path_str\n",
        "\n",
        "                    # Build full path\n",
        "                    target_path = os.path.join(WORKSPACE, \"models\", folder_part)\n",
        "                    os.makedirs(target_path, exist_ok=True)\n",
        "\n",
        "                    %cd {target_path}\n",
        "                    print(f\"üì• Downloading: {filename_part} in models/{folder_part}\")\n",
        "                    download_logic(url, filename_part)\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è Skipping invalid entry: {model}\")\n",
        "\n",
        "        print(\"\\n‚úÖ Download process finished!\")\n",
        "        %cd {WORKSPACE}\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ùå Error: The content of MODELOS_PERSONALIZADOS is not a valid JSON.\")\n",
        "    except NameError:\n",
        "        print(\"‚ùå Error: The 'WORKSPACE' variable is not defined. Run the installation cell first.\")\n",
        "\n",
        "descargar_modelos_custom()"
      ],
      "metadata": {
        "id": "XLXxBZ_PVKPm",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}